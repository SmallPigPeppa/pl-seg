{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766cadc-cc3b-41e4-848f-76c78f16d784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac4594-754a-49b3-b970-2b59baae0a42",
   "metadata": {},
   "source": [
    "# Train a Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce36537-fa13-4fb3-9ada-ca551ba96c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from fastai.vision.all import *\n",
    "from typing import List, Union, Tuple\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "\n",
    "from segmentation.metrics import *\n",
    "from segmentation.model import SegmentationModel\n",
    "from segmentation.train_utils import benchmark_inference_time, save_model_to_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ae123-0a27-454c-8a4e-4817b16d4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=\"CamVid-Segmentation\"\n",
    "ENTITY=\"av-demo\"\n",
    "IMAGE_SHAPE = (720, 960)\n",
    "SEED = 42\n",
    "RUN_NAME = \"baseline-train-3\"\n",
    "JOB_TYPE = \"train\"\n",
    "\n",
    "ARTIFACT_ID = \"camvid-dataset:latest\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_RESIZE_FACTOR = 4\n",
    "VALIDATION_SPLIT_PCT = 0.2\n",
    "HIDDEN_DIM = 256\n",
    "BACKBONE = \"resnet50\"\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_EPOCHS = 15\n",
    "\n",
    "INFERENCE_BATCH_SIZE = 8\n",
    "NUM_WARMUP_ITERS = 10\n",
    "NUM_INFERENCE_BENCHMARK_ITERS = 100\n",
    "\n",
    "MODE = None #\"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d72582-8a20-440e-8909-8549c8196766",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf22ef-00d9-43b0-abdc-903df6012dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=PROJECT,\n",
    "    name=RUN_NAME,\n",
    "    entity=ENTITY,\n",
    "    job_type=JOB_TYPE,\n",
    "    mode=MODE,\n",
    "    config={\n",
    "        \"artifact_id\": ARTIFACT_ID,\n",
    "        \"image_shape\": IMAGE_SHAPE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"image_resize_factor\": IMAGE_RESIZE_FACTOR,\n",
    "        \"validation_split\": VALIDATION_SPLIT_PCT,\n",
    "        \"hidden_dims\": HIDDEN_DIM,\n",
    "        \"backbone\": BACKBONE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"train_epochs\": TRAIN_EPOCHS,\n",
    "        \"inference_batch_size\": INFERENCE_BATCH_SIZE,\n",
    "        \"num_warmup_iters\": NUM_WARMUP_ITERS,\n",
    "        \"num_inference_banchmark_iters\": NUM_INFERENCE_BENCHMARK_ITERS\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b03ddbe-0258-4d27-b393-dcfb1576e4f8",
   "metadata": {},
   "source": [
    "## DataLoader for SegmentationDataLoader for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5880664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fn):\n",
    "    return fn.parent.parent/\"labels\"/f\"{fn.stem}_P{fn.suffix}\"\n",
    "\n",
    "\n",
    "def get_dataloaders(\n",
    "    artifact_id: str, # the name of the artifact\n",
    "    batch_size: int,  # the batch size for training, 2x for val\n",
    "    resize_factor: int, # a integer resize factor for training\n",
    "    validation_split_pct: float, # the validation percentage of data to be used in [0,1] \n",
    "    seed: int # the seed\n",
    "):\n",
    "    \"\"\"Grab an artifact and creating a Pytorch DataLoader\"\"\"\n",
    "    artifact = wandb.use_artifact(artifact_id, type='dataset')\n",
    "    artifact_dir = Path(artifact.download())\n",
    "    codes = np.loadtxt(artifact_dir/'codes.txt', dtype=str)\n",
    "    fnames = get_image_files(artifact_dir/\"images\")\n",
    "    class_labels = {k: v for k, v in enumerate(codes)}\n",
    "    \n",
    "    image_shape = load_image(fnames[0]).shape\n",
    "    \n",
    "    return SegmentationDataLoaders.from_label_func(\n",
    "        artifact_dir,\n",
    "        bs=batch_size,\n",
    "        fnames=fnames,\n",
    "        label_func=label_func,\n",
    "        codes=codes,\n",
    "        item_tfms=Resize((\n",
    "            image_shape[0] // resize_factor,\n",
    "            image_shape[1] // resize_factor\n",
    "        )),\n",
    "        valid_pct=validation_split_pct,\n",
    "        seed=seed\n",
    "    ), class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3813596-79cb-4784-b1a0-01f18b1aaac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader, class_labels = get_dataloaders(\n",
    "    artifact_id=ARTIFACT_ID,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize_factor=IMAGE_RESIZE_FACTOR,\n",
    "    validation_split_pct=VALIDATION_SPLIT_PCT,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "data_loader.show_batch(max_n=4, vmin=1, vmax=30, figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219ae16-e20d-41de-bfb9-8c78eef3af8d",
   "metadata": {},
   "source": [
    "## Training and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7bb98a-99c3-4b69-af6a-163612ae5cca",
   "metadata": {},
   "source": [
    "Let's log a bucnh of useful data for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1d864-91f9-491b-a545-046a01476af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_parameters(model):\n",
    "    \"Get total number of model params\"\n",
    "    with torch.no_grad():\n",
    "        num_params = sum(p.numel() for p in model.parameters())\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332f794-4d26-496f-b52f-9ce1d4d4a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, test_dl=None, max_n=None):\n",
    "    \"Return the samples = (x,y) and outputs (model predictions decoded), and predictions (raw preds)\" \n",
    "    if test_dl is None:\n",
    "        test_dl = learn.dls.valid\n",
    "    inputs, predictions, targets, outputs = learn.get_preds(dl=test_dl, with_input=True, with_decoded=True)\n",
    "    x, y, samples, outputs = learn.dls.valid.show_results(\n",
    "        tuplify(inputs) + tuplify(targets), outputs, show=False, max_n=max_n\n",
    "    )\n",
    "    return samples, outputs, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8512276-b961-4bed-91bb-55149ab3337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(\n",
    "    data_loader,\n",
    "    backbone: str,\n",
    "    hidden_dim: int,\n",
    "    num_classes: int,\n",
    "    checkpoint_file: Union[None, str, Path],\n",
    "    loss_func,\n",
    "    metrics: List,\n",
    "    log_preds: bool = False\n",
    "):\n",
    "    model = SegmentationModel(backbone, hidden_dim, num_classes=num_classes)\n",
    "    mixed_precision_callback = MixedPrecision()\n",
    "    wandb_callback = WandbCallback(log_model=False, log_preds=log_preds)\n",
    "    learner = Learner(\n",
    "        data_loader,\n",
    "        model,\n",
    "        loss_func=loss_func,\n",
    "        metrics=metrics,\n",
    "        cbs=[mixed_precision_callback, wandb_callback],\n",
    "    )\n",
    "    if checkpoint_file is not None:\n",
    "        load_model(checkpoint_file, learner.model, opt=None, with_opt=False)\n",
    "        # learner.load(checkpoint_file)\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1b301-3a35-4c88-8271-6532f533cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(\n",
    "    data_loader,\n",
    "    backbone=BACKBONE,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_classes=len(class_labels),\n",
    "    checkpoint_file=None,\n",
    "    loss_func=FocalLossFlat(axis=1),\n",
    "    metrics=[DiceMulti(), foreground_acc],\n",
    "    log_preds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb065b72-4f9e-4f1c-b274-43554fee2136",
   "metadata": {},
   "source": [
    "## Log preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e17b19-4310-4daf-b33b-b247535007ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_from_dl(learn, test_dl, class_labels):\n",
    "    samples, outputs, predictions = get_predictions(learn, test_dl)\n",
    "    table = create_dice_table(samples, outputs, predictions, class_labels)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b077e-01f3-48c6-be41-8a316870cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fine_tune(10, 1e-3)\n",
    "learn.fit_one_cycle(TRAIN_EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d9301-d599-4f1c-aaf2-94ed0e9c1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_table = table_from_dl(learn, learn.dls.valid, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb02af0-8ed0-4d6a-8dc5-4e9ff80ba134",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({f\"Predictions_Table\": pred_table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95407ffb-f9e1-4fd5-a9aa-8b72bd4a5ba8",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1f67f-cbbd-45ac-94c7-2f72e23ce339",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_to_artifacts(\n",
    "    learn.model, \n",
    "    f\"Unet_{BACKBONE}\", \n",
    "    image_shape=IMAGE_SHAPE,\n",
    "    artifact_name=f\"{run.name}-saved-model\",\n",
    "    metadata={\n",
    "        \"backbone\": BACKBONE,\n",
    "        \"hidden_dims\": HIDDEN_DIM,\n",
    "        \"input_size\": IMAGE_SHAPE,\n",
    "        \"class_labels\": class_labels\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c00015-bc1c-498d-99d2-1e310484f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = f\"Unet_{BACKBONE}_traced.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be17799-9569-488d-9908-885b5f1116d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference_time(\n",
    "    model_file,\n",
    "    image_shape: tuple[int, int],\n",
    "    batch_size: int,\n",
    "    num_warmup_iters: int,\n",
    "    num_iter: int,\n",
    "    seed: int,\n",
    "):\n",
    "    model = torch.jit.load(model_file).cuda()\n",
    "    \n",
    "    dummy_input = torch.randn(\n",
    "        batch_size, 3, image_shape[0] // 2, image_shape[0] // 2, dtype=torch.float\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    starter, ender = (\n",
    "        torch.cuda.Event(enable_timing=True),\n",
    "        torch.cuda.Event(enable_timing=True),\n",
    "    )\n",
    "    timings = np.zeros((num_iter, 1))\n",
    "\n",
    "    print(\"Warming up GPU...\")\n",
    "    for _ in progress_bar(range(num_warmup_iters)):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "    print(\n",
    "        f\"Computing inference time over {num_iter} iterations with batches of {batch_size} images...\"\n",
    "    )\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for step in progress_bar(range(num_iter)):\n",
    "            starter.record()\n",
    "            _ = model(dummy_input)\n",
    "            ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            timings[step] = starter.elapsed_time(ender)\n",
    "\n",
    "    return np.sum(timings) / (num_iter * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2107052-773a-4760-a6c6-6848f897eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "inference_time = benchmark_inference_time(model_file,\n",
    "                    batch_size=INFERENCE_BATCH_SIZE,\n",
    "                    image_shape=IMAGE_SHAPE,\n",
    "                    num_warmup_iters=NUM_WARMUP_ITERS,\n",
    "                    num_iter=NUM_INFERENCE_BENCHMARK_ITERS,\n",
    "                    seed=SEED\n",
    "                    )\n",
    "\n",
    "wandb.log({\"inference_time\":inference_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27012816-d7cb-41ae-8df6-4c4728389e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
