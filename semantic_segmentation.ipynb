{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce36537-fa13-4fb3-9ada-ca551ba96c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b03ddbe-0258-4d27-b393-dcfb1576e4f8",
   "metadata": {},
   "source": [
    "## CamVid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad833a0-77ef-4354-a1af-2bcba0ad11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.CAMVID)\n",
    "codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    "fnames = get_image_files(path/\"images\")\n",
    "class_labels = {k: v for k, v in enumerate(codes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8deecc1-41d9-4796-a8c4-e4abb3cbe293",
   "metadata": {},
   "source": [
    "### Logging on Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334d55b-0a4a-48f8-9dd3-2516b0473a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dataset():\n",
    "    image_files = sorted(glob.glob(os.path.join(str(path), \"images/*.png\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(str(path), \"labels/*.png\")))\n",
    "    temp_zip = list(zip(image_files, label_files))\n",
    "    random.shuffle(temp_zip)\n",
    "    image_files, label_files = zip(*temp_zip)\n",
    "    table_data = []\n",
    "    for idx in tqdm(range(len(image_files))):\n",
    "        image = np.array(Image.open(image_files[idx]))\n",
    "        mask_data = np.array(Image.open(label_files[idx]))\n",
    "        table_data.append([\n",
    "            wandb.Image(image),\n",
    "            wandb.Image(image, masks={\n",
    "                \"predictions\": {\n",
    "                    \"mask_data\": mask_data,\n",
    "                    \"class_labels\": class_labels\n",
    "                }\n",
    "            })\n",
    "        ])\n",
    "\n",
    "\n",
    "    with wandb.init(project=\"autonomous-vehicle-status-report\", entity=\"geekyrakshit\"):\n",
    "        wandb.log({\"CamVid Dataset\": wandb.Table(\n",
    "            data=table_data, columns=[\"Images\", \"Segmentation Masks\"]\n",
    "        )})\n",
    "\n",
    "\n",
    "# Uncomment the following line to log the CamVid Dataset as an artifact\n",
    "# log_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e472d0-d8da-4b13-8b3d-d8af9ed53220",
   "metadata": {},
   "source": [
    "### DataLoader for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc5a2a-b0f3-4738-aeba-2d6187de089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fn):\n",
    "    return path/\"labels\"/f\"{fn.stem}_P{fn.suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379d621-7189-4f9f-881c-77b9d9104703",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = SegmentationDataLoaders.from_label_func(\n",
    "    path, bs=8, fnames=fnames, label_func=label_func, codes=codes, \n",
    "    item_tfms=Resize((720 // 4, 960 // 4)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6733f-092e-442b-aa38-0402b541b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.show_batch(max_n=4, vmin=1, vmax=30, figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc7cd4-8175-4b57-b303-43cfa05b4cbc",
   "metadata": {},
   "source": [
    "## Semantic Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a95b4-8b78-47ee-89a8-c52e08a88dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 1,\n",
    "        groups: int = 1,\n",
    "        stride: int = 1,\n",
    "        activation: bool = True\n",
    "    ):\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride=stride,\n",
    "                padding=kernel_size // 2,\n",
    "                groups=groups,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        ] + (\n",
    "            [nn.ReLU6(inplace=True)] if activation else []\n",
    "        )\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335dcd5-22e7-4528-a04c-078245b9250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRPBlock(nn.Module):\n",
    "    \"\"\"A bunch of convs and a maxpool with a tricky forward\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_stages=1, use_groups=False):\n",
    "        super().__init__()\n",
    "        groups = in_channels if use_groups else 1\n",
    "        convs = [nn.Conv2d(\n",
    "            in_channels if (i == 0) else out_channels,\n",
    "            out_channels, kernel_size=1, bias=False, groups=groups\n",
    "        ) for i in range(num_stages)]\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"y = x + f(x) + f(f(x)) + f(f(f(x)))...\"\n",
    "        out = x\n",
    "        for conv in self.convs:\n",
    "            out = conv(self.pool(out))\n",
    "            x = out + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b8baf-691d-4035-8dae-a4c7398d5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, in_up, in_side, out_channels, kernel_size=1, num_stages=4, use_groups=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv_up   = ConvLayer(in_up, out_channels, kernel_size)\n",
    "        self.conv_side = ConvLayer(in_side, out_channels, kernel_size)\n",
    "        self.crp = CRPBlock(\n",
    "            out_channels, out_channels, num_stages=num_stages, use_groups=use_groups\n",
    "        )\n",
    "\n",
    "    def forward(self, side_input, up_input):\n",
    "        up_input = self.conv_up(up_input)\n",
    "        side_input = self.conv_side(side_input)\n",
    "        if up_input.shape[-2:] != side_input.shape[-2:]:\n",
    "            up_input = F.interpolate(\n",
    "                up_input, size=side_input.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "        out = self.crp(F.relu(up_input + side_input))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24c8e8-5d65-49fe-838f-762462ae04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicUnet(nn.Module):\n",
    "    \"\"\"\n",
    "    A Unet that take almost any backbone from timm\n",
    "    Reference: https://github.com/tcapelle/hydra_net/blob/master/hydranet/models.py#L13\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone=\"mobilenetv2_100\", dim=256):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(backbone, pretrained=True, features_only=True)\n",
    "        # passing dummy tensor to get sizes\n",
    "        dummy_tensor = torch.rand([1, 3, 64, 64])\n",
    "        features = self.encoder(dummy_tensor)\n",
    "        ch_sizes = [list(f.shape)[1] for f in features][::-1]\n",
    "        self.upsample_blocks = nn.ModuleList()\n",
    "        self.mid_conv = ConvLayer(ch_sizes[0], dim, 3)\n",
    "        for i, ch_size in enumerate(ch_sizes[1:]):\n",
    "            self.upsample_blocks.append(\n",
    "                UnetBlock(\n",
    "                    dim, ch_size, out_channels=dim, use_groups=(i==(len(features)-2))\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape\n",
    "        # features reversed in order\n",
    "        features = self.encoder(x)[::-1]\n",
    "        # put last feature on dim of the model\n",
    "        x = self.mid_conv(features[0])\n",
    "        # upsample blocks with shortcurts from the sides\n",
    "        for f, ublock in zip(features[1:], self.upsample_blocks):\n",
    "            x = ublock(f, x)\n",
    "        x = F.interpolate(x, size=input_shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa3325-d742-44bd-8858-c7d1c3566c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self, backbone=\"mobilenetv2_100\", hidden_dim=256, num_classes=21):\n",
    "        super().__init__()\n",
    "        self.backbone = DynamicUnet(backbone, dim=hidden_dim)\n",
    "        self.segmentation_head = nn.Sequential(\n",
    "            ConvLayer(hidden_dim, hidden_dim),\n",
    "            nn.Conv2d(hidden_dim, num_classes, kernel_size=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        backbone_out = self.backbone(x)\n",
    "        return self.segmentation_head(backbone_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9be62-36df-4776-909e-3c23cdb6c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a836fd9-3237-49ec-9e1d-cc091747fbc3",
   "metadata": {},
   "source": [
    "## Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881291b-e656-4e46-ae20-410b79fc3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://forums.fast.ai/t/feedback-on-using-custom-dice-loss-in-multi-class-semantic-segmentation/70431/5\n",
    "\n",
    "def _one_hot(x, classes, axis=1):\n",
    "    \"Target mask to one hot\"\n",
    "    return torch.stack([torch.where(x==c, 1,0) for c in range(classes)], axis=axis)\n",
    "\n",
    "class DiceLoss:\n",
    "    \"Dice coefficient metric for binary target in segmentation\"\n",
    "    def __init__(self, axis=1, smooth=1): \n",
    "        store_attr()\n",
    "    \n",
    "    def __call__(self, pred, targ):\n",
    "        targ = _one_hot(targ, pred.shape[1])\n",
    "        pred, targ = flatten_check(self.activation(pred), targ)\n",
    "        inter = (pred * targ).sum()\n",
    "        union = (pred + targ).sum()\n",
    "        return 1 - (2. * inter + self.smooth) / (union + self.smooth)\n",
    "    \n",
    "    def activation(self, x):\n",
    "        return F.softmax(x, dim=self.axis)\n",
    "    \n",
    "    def decodes(self, x):\n",
    "        return x.argmax(dim=self.axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219ae16-e20d-41de-bfb9-8c78eef3af8d",
   "metadata": {},
   "source": [
    "## Training and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15504108-fc34-4f14-9b79-5e15a626fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learner):\n",
    "    inputs, predictions, targets, outputs = learner.get_preds(with_input=True, with_decoded=True)\n",
    "    x, y, samples, outputs = learner.dls.valid.show_results(\n",
    "        tuplify(inputs) + tuplify(targets), outputs, show=False, max_n=36\n",
    "    )\n",
    "    return samples, outputs, predictions\n",
    "\n",
    "\n",
    "def create_wandb_table(samples, outputs, predictions):\n",
    "    \"Creates a wandb table with predictions and targets side by side\"\n",
    "    table = wandb.Table(columns=[\"Image\", \"Predicted Mask\", \"Ground Truth\"])\n",
    "    for (image, label), pred_label in zip(samples, outputs):\n",
    "        image = image.permute(1,2,0)\n",
    "        table.add_data(\n",
    "            wandb.Image(image),\n",
    "            wandb.Image(\n",
    "                image,\n",
    "                masks={\n",
    "                    \"predictions\":  {\n",
    "                        'mask_data':  pred_label[0].numpy(),\n",
    "                        'class_labels':class_labels\n",
    "                    }\n",
    "                }\n",
    "            ),\n",
    "            wandb.Image(\n",
    "                image,\n",
    "                masks={\n",
    "                    \"ground truths\": {\n",
    "                        'mask_data': label.numpy(),\n",
    "                        'class_labels':class_labels\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ae222-8e32-42b4-9575-3312b860ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"autonomous-vehicle-status-report\",\n",
    "    entity=\"geekyrakshit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561a374-aff3-4b30-98fc-62220b0882d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model = SegmentationModel(num_classes=len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1cf4c-126b-4ae0-a960-9091b7917337",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_callback = SaveModelCallback(fname=\"unet_mobilenetv2_100\")\n",
    "mixed_precision_callback = MixedPrecision()\n",
    "wandb_callback = WandbCallback(log_preds=False)\n",
    "\n",
    "\n",
    "learner = Learner(\n",
    "    data_loader,\n",
    "    segmentation_model,\n",
    "    # loss_func=CrossEntropyLossFlat(axis=1),\n",
    "    # loss_func=FocalLossFlat(axis=1),\n",
    "    loss_func=DiceLoss(axis=1),\n",
    "    metrics=[DiceMulti(), foreground_acc],\n",
    "    cbs=[save_model_callback, mixed_precision_callback, wandb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0b8dd-71bb-4905-aff0-fb507ca6c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b077e-01f3-48c6-be41-8a316870cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fine_tune(10, 1e-3)\n",
    "learner.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296f17b-e944-4a83-9b6c-26883147e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.show_results(max_n=4, figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6da99-127d-46ad-bd92-37900d08e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, outputs, predictions = get_predictions(learner)\n",
    "table = create_wandb_table(samples, outputs, predictions)\n",
    "wandb.log({f\"Predictions_{run.name}\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf7bf8-bb74-4464-b562-04cc3b12ac21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420ef2c-0ad8-42f1-99ee-350693858141",
   "metadata": {},
   "source": [
    "## Training with Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666684fd-cbfa-4b32-9f81-df19609222e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = {\n",
    "    \"batch_size\": 8,\n",
    "    \"image_height\": 720,\n",
    "    \"image_width\": 960,\n",
    "    \"image_resize_factor\": 4,\n",
    "    \"backbone\": \"mobilenetv2_100\",\n",
    "    \"num_epochs\": 5,\n",
    "    \"loss_function\": \"categorical_cross_entropy\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"fit\": \"fit\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae286a-edd8-42fa-8a0f-22cffc0bd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn():\n",
    "    run = wandb.init(\n",
    "        project=\"autonomous-vehicle-status-report\",\n",
    "        entity=\"geekyrakshit\",\n",
    "        config=experiment_configs\n",
    "    )\n",
    "    data_loader = SegmentationDataLoaders.from_label_func(\n",
    "        path, bs=wandb.config.batch_size,\n",
    "        fnames=fnames, label_func=label_func, codes=codes, \n",
    "        item_tfms=Resize((\n",
    "            wandb.config.image_height // wandb.config.image_resize_factor,\n",
    "            wandb.config.image_width // wandb.config.image_resize_factor\n",
    "        )),\n",
    "    )\n",
    "    segmentation_model = SegmentationModel(\n",
    "        backbone=wandb.config.backbone, num_classes=len(codes)\n",
    "    )\n",
    "    loss_fn = None\n",
    "    if wandb.config.loss_function == \"categorical_cross_entropy\":\n",
    "        loss_fn = CrossEntropyLossFlat(axis=1)\n",
    "    elif wandb.config.loss_function == \"focal\":\n",
    "        loss_fn = FocalLossFlat(axis=1)\n",
    "    elif wandb.config.loss_function == \"dice\":\n",
    "        loss_fn = DiceLoss(axis=1)\n",
    "    learner = Learner(\n",
    "        data_loader,\n",
    "        segmentation_model,\n",
    "        loss_func=loss_fn,\n",
    "        metrics=[DiceMulti(), foreground_acc],\n",
    "        cbs=[\n",
    "            SaveModelCallback(fname=f\"unet_{wandb.config.backbone}\"),\n",
    "            MixedPrecision(),\n",
    "            WandbCallback(log_preds=False)\n",
    "        ]\n",
    "    )\n",
    "    if wandb.config.fit == \"fit\":\n",
    "        learner.fit_one_cycle(\n",
    "            wandb.config.num_epochs,\n",
    "            wandb.config.learning_rate\n",
    "        )\n",
    "    else:\n",
    "        learner.fine_tune(\n",
    "            wandb.config.num_epochs,\n",
    "            wandb.config.learning_rate\n",
    "        )\n",
    "    samples, outputs, predictions = get_predictions(learner)\n",
    "    table = create_wandb_table(samples, outputs, predictions)\n",
    "    wandb.log({f\"Predictions-{run.name}\": table})\n",
    "    wandb.log({\"Model Params\": get_model_parameters(model)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd099456-74fd-4e6c-b931-ce163336cc65",
   "metadata": {},
   "source": [
    "### Sweeping over to find the best Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4b36e-abec-4c46-8cc7-3758b45040f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config_backbone = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"valid_loss\", \"goal\": \"minimize\"},\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 5,\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [4, 8, 16]},\n",
    "        \"image_resize_factor\": {\"values\": [2, 4]},\n",
    "        \"backbone\": {\n",
    "            \"values\": [\n",
    "                \"mobilenetv2_100\",\n",
    "                \"mobilenetv3_small_050\",\n",
    "                \"mobilenetv3_large_100\",\n",
    "                \"resnet18\",\n",
    "                \"resnet34\",\n",
    "                \"resnet50\",\n",
    "                \"vgg19\",\n",
    "                \"vgg16\"\n",
    "            ]\n",
    "        },\n",
    "        \"loss_function\": {\"values\": [\"categorical_cross_entropy\", \"focal\", \"dice\"]},\n",
    "        \"learning_rate\": {\"values\": [1e-2, 1e-3, 1e-4]},\n",
    "        \"fit\": {\"values\": [\"fit\", \"fine-tune\"]}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b9a3e-e72d-4345-afa7-aaa8897473de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config_backbone, project=\"autonomous-vehicle-status-report\")\n",
    "wandb.agent(sweep_id, function=train_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d66a9-607f-4158-b914-6416eed00527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
